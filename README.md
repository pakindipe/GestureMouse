# ğŸ–ï¸ Gesture Mouse Control  
**AI-Inspired Gesture-Based Mouse Control using Computer Vision**

Control your computerâ€™s mouse using natural hand gestures in real time â€” no hardware beyond a webcam required.

This project explores **gesture-based humanâ€“computer interaction (HCI)** by translating hand movements into full OS-level mouse control, including cursor movement, clicking, dragging, scrolling, and adaptive precision control.

Built entirely in **Python** using **computer vision and intelligent intent detection**.

---

## ğŸš€ Features

### ğŸ¯ Core Controls
- ğŸ‘‰ **Index finger** â€” Move cursor
- ğŸ¤ **Pinch (tap)** â€” Left click
- ğŸ¤ **Pinch (hold)** â€” Drag & drop
- âœŒï¸ **Index + Middle** â€” Scroll
- âŒ¨ï¸ **Spacebar** â€” Pause / Unpause
- â‹ **ESC** â€” Exit program

---

### ğŸ§  Intelligent Interaction (Advanced)
- **Adaptive cursor speed**
  - Fast hand motion â†’ fast cursor
  - Slow/steady motion â†’ precision control
- **Slowdown zones**
  - Automatic precision near screen edges
- **Gesture confidence scoring**
  - Reduces accidental actions
- **Intent detection with hysteresis**
  - Prevents gesture flickering
  - Chooses the most likely action each frame
- **Virtual FOV expansion**
  - Makes narrow laptop webcams feel wider

---

### ğŸ“Š Live HUD
- Current intent (MOVE / SCROLL / CLICK / DRAG / IDLE)
- Gesture confidence bar
- FPS (performance monitoring)
- Pinch distance
- Adaptive gain & velocity diagnostics

---

## ğŸ› ï¸ Tech Stack

| Technology | Purpose |
|----------|--------|
| **Python** | Core application logic |
| **OpenCV** | Webcam input & visualization |
| **MediaPipe Hands** | Real-time hand landmark tracking (21 points) |
| **PyAutoGUI** | OS-level mouse control |
| **Math / Geometry** | Gesture detection & smoothing |
| **HCI Principles** | Adaptive speed, confidence, intent modeling |

---

## ğŸ§© How It Works (High Level)

1. Webcam feed captured using OpenCV  
2. MediaPipe detects and tracks hand landmarks in real time  
3. Landmarks are analyzed to compute:
   - Finger states
   - Pinch distance
   - Hand velocity
4. A confidence-based intent system selects the most likely gesture
5. Cursor movement uses:
   - Smoothing
   - Adaptive gain
   - Edge slowdown zones
6. PyAutoGUI sends mouse events to the OS

---

## âš™ï¸ Installation

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/pakindipe/GestureMouse.git
cd GestureMouse
```
2ï¸âƒ£ Create & activate virtual environment
python -m venv venv


Windows

venv\Scripts\activate

3ï¸âƒ£ Install dependencies
pip install -r requirements.txt


If you donâ€™t have a requirements.txt yet, install manually:

pip install opencv-python mediapipe pyautogui numpy

â–¶ï¸ Run the Program
python gesture_mouse.py


Make sure your webcam is unobstructed and your hand is well-lit.

ğŸ–¥ï¸ Hardware Notes

Works with built-in laptop webcams (tested on ROG Zephyrus)

No GPU required

Higher camera resolution (720p) improves tracking stability

ğŸ“ˆ Current Capabilities

Full mouse replacement

Real-time performance (~30â€“60 FPS)

Robust against noisy gestures

Designed for extensibility

ğŸ”® Planned Enhancements

Gesture classifier using machine learning

Auto-calibration wizard

Right-click & double-click gestures

Per-application gesture profiles

Gesture analytics & heatmaps

ğŸ¯ Why This Project Matters

This is not just a gesture demo.

It demonstrates:

Computer vision fundamentals

Real-time system design

Humanâ€“computer interaction principles

Intelligent input modeling

Practical OS automation

ğŸ‘¤ Author

Pakindi Pe

â­ If You Like This Project

Give it a star â­ â€” it helps a lot!


---
