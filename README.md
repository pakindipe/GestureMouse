# Gesture Mouse Control  
**AI-Inspired Gesture-Based Mouse Control using Computer Vision**

Control your computer‚Äôs mouse using natural hand gestures in real time, no hardware beyond a webcam required.

This project explores **gesture-based human‚Äìcomputer interaction (HCI)** by translating hand movements into full OS-level mouse control, including cursor movement, clicking, dragging, scrolling, and adaptive precision control.

Built entirely in **Python** using **computer vision and intelligent intent detection**.

---

## Features

### Core Controls
- üëâ **Index finger** ‚Äî Move cursor
- ü§è **Pinch (tap)** ‚Äî Left click
- ü§è **Pinch (hold)** ‚Äî Drag & drop
- ‚úåÔ∏è **Index + Middle** ‚Äî Scroll
- ‚å®Ô∏è **Spacebar** ‚Äî Pause / Unpause
- ‚éã **ESC** ‚Äî Exit program

---

### Intelligent Interaction (Advanced)
- **Adaptive cursor speed**
  - Fast hand motion ‚Üí fast cursor
  - Slow/steady motion ‚Üí precision control
- **Slowdown zones**
  - Automatic precision near screen edges
- **Gesture confidence scoring**
  - Reduces accidental actions
- **Intent detection with hysteresis**
  - Prevents gesture flickering
  - Chooses the most likely action each frame
- **Virtual FOV expansion**
  - Makes narrow laptop webcams feel wider

---

### Live HUD
- Current intent (MOVE / SCROLL / CLICK / DRAG / IDLE)
- Gesture confidence bar
- FPS (performance monitoring)
- Pinch distance
- Adaptive gain & velocity diagnostics

---

## Tech Stack

| Technology | Purpose |
|----------|--------|
| **Python** | Core application logic |
| **OpenCV** | Webcam input & visualization |
| **MediaPipe Hands** | Real-time hand landmark tracking (21 points) |
| **PyAutoGUI** | OS-level mouse control |
| **Math / Geometry** | Gesture detection & smoothing |
| **HCI Principles** | Adaptive speed, confidence, intent modeling |

---

## How It Works (High Level)

1. Webcam feed captured using OpenCV  
2. MediaPipe detects and tracks hand landmarks in real time  
3. Landmarks are analyzed to compute:
   - Finger states
   - Pinch distance
   - Hand velocity
4. A confidence-based intent system selects the most likely gesture
5. Cursor movement uses:
   - Smoothing
   - Adaptive gain
   - Edge slowdown zones
6. PyAutoGUI sends mouse events to the OS

---

## Installation

### 1Ô∏è‚É£ Clone the repository
```bash
git clone https://github.com/pakindipe/GestureMouse.git
cd GestureMouse
```
### 2Ô∏è‚É£ Create & activate virtual environment
```bash
python -m venv venv
```
Windows
```bash
venv\Scripts\activate
```
### 3Ô∏è‚É£ Install dependencies
```bash
pip install -r requirements.txt
```
If you don‚Äôt have a requirements.txt yet, install manually:
```bash
pip install opencv-python mediapipe pyautogui numpy
```
### ‚ñ∂Ô∏è Run the Program
```bash
python gesture_mouse.py
```
Make sure your webcam is unobstructed and your hand is well-lit.

---

## Hardware Notes
- Works with built-in laptop webcams (tested on ROG Zephyrus G14)
- No GPU required
- Higher camera resolution (720p) improves tracking stability

---

## Current Capabilities
- Full mouse replacement
- Real-time performance (~30‚Äì60 FPS)
- Robust against noisy gestures
- Designed for extensibility

---

## Planned Enhancements
- Gesture classifier using machine learning
- Auto-calibration wizard
- Right-click & double-click gestures
- Per-application gesture profiles
- Gesture analytics & heatmaps

---

## Key Things I Learned From Developing This Project
- Computer vision fundamentals
- Real-time system design
- Human‚Äìcomputer interaction principles
- Intelligent input modeling
- Practical OS automation

---

### Author
Philip Akindipe




---
